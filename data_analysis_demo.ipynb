{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Q1BplXllLG-"
      },
      "source": [
        "# Open States Summit - Data Analysis Track\n",
        "\n",
        "### Introduction\n",
        "This track is for people who are interested in obtaining data from Open States, understanding it, and performing quantitative analysis on that data. You will receive a tutorial on how to access data via the API or our bulk offerings, and an example of quantitative analysis in Python.\n",
        "\n",
        "\n",
        "## Public Policy Data\n",
        "The legislative process at the state and federal level creates significant amounts of data that can be used to understand, predict and affect future legislation. A few examples of the data product of our legislation is:\n",
        "\n",
        "- Bills: Bill texts, bills metadata (date introduced, proposer)\n",
        "- People: Congressman state, age, chamber\n",
        "- Vote: Number of votes, amount of voting processes\n",
        "- Committees: Committee members, votes, bills, topics\n",
        "- Sessions: Start, end, bills introduced\n",
        "- etc.\n",
        "\n",
        "There are a few ways to access policy data available in Open States. Some of them are:   \n",
        "- Bulk data\n",
        "    - Json, CSV, and database dumps\n",
        "    - Free access\n",
        "    - Bills and People data\n",
        "- API v3\n",
        "   - Create free account at openstates.com\n",
        "   - Copy and save the Api Key\n",
        "   - Swagger UI documentation\n",
        "- `pyopenstates` Python library"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dYEXDWDWlLHD"
      },
      "source": [
        "### Import libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ooRV70t1lLHD"
      },
      "outputs": [],
      "source": [
        "import requests, zipfile, io"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O7Xk5qMilLHG"
      },
      "source": [
        "### Download data from bulk export"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NlNwI9hGlLHH"
      },
      "outputs": [],
      "source": [
        "zip_file_url = 'https://data.openstates.org/csv/latest/MN_2021-2022_csv_ANkWj6NP3kGwnwwxJ3gk6.zip'\n",
        "r = requests.get(zip_file_url)\n",
        "z = zipfile.ZipFile(io.BytesIO(r.content))\n",
        "z.extractall()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bLv4V1ZElLHH"
      },
      "outputs": [],
      "source": [
        "!head MN/2021-2022/MN_2021-2022_bills.csv"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4-SVN-TklLHI"
      },
      "source": [
        "## Data Analysis for Public Policy\n",
        "Public Policy affects the life of every citizen and business in the country, in small and big ways, at the federal, state or city level. Companies spend millions of dollars trying to influence new legislation. However, since most policy data is public, individuals and smaller groups can use Open Source tools and services to get policy data and help them achieve their goals.\n",
        "\n",
        "Some interesting policy questions subject to data analysis are:\n",
        "- Who will support this bill?\n",
        "- How likely is this bill to pass?\n",
        "- Whatâ€™s the legislation regarding this topic?\n",
        "- What is the relevant information in this bill?\n",
        "\n",
        "It's important to note that not all policy analysis will be successful, by a huge amount of factors including low frequency events (ex: # of sessions), unavailable data (ex: backdoor bill negotiations), specialized legal jargon, etc. This however should not discourage us from consciously analyzing existing and high quality data.  \n",
        "\n",
        "Given the amount and types of data generated, we have multiple opportunities to analyze legislative events: data exploration and visualization, statistical tests on voting data, votes prediction, bill classification and others.\n",
        "\n",
        "While there's some structured policy data, some of the most common and relevant resources (like bills and regulations) come in the form of unstructured text. As so, it's logical step to use NLP methods common in text heavy fields like Legal, Medicine, and others.   \n",
        "\n",
        "### Why is NLP relevant for Policy Analysis?\n",
        "\n",
        "Natural language processing studies interactions between computers and humans using natural languages, intersecting the fields of Linguistics and Computer Science. Natural Language Processing has seen significant advances in the last decade, allowing the deployment of automated ML systems to solve tasks like:  \n",
        "\n",
        "- **Text generation**: Create new text from a given input.\n",
        "- **Name entity recognition (NER)**: label each word with the entity it represents (person, date, location, etc.).\n",
        "- **Question answering**: extract an answer from the context, given the context and a question.\n",
        "- **Summarization**: generate a summary of a long sequence of text or document.\n",
        "- **Translation**: translate text into another languages."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gBCPm2OJlLHJ"
      },
      "source": [
        "## Bill Topic Detection"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xnyMZ1rflLHJ"
      },
      "source": [
        "### Objective\n",
        "A simple way for a person to identify which bills they care about is to select the ones that affect the policy topics they care about. Since not all states provide the related policies for a given bill, it would be useful to create a system to identify bills policy topics.  \n",
        "For the sake of simplicity, we will only use bill names to find the possible topics."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6KqFndD0lLHA"
      },
      "source": [
        "### Install required libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Am_X8bPHlLHB"
      },
      "outputs": [],
      "source": [
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6onYvPKdlLHK"
      },
      "source": [
        "### Import libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9DbNlwwMlLHL"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import plotly.express as px\n",
        "\n",
        "from sklearn.preprocessing import normalize\n",
        "from sklearn.cluster import KMeans, DBSCAN, MeanShift\n",
        "from sklearn.manifold import TSNE\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from transformers import pipeline\n",
        "from ast import literal_eval"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GrmSXSgZlLHL"
      },
      "source": [
        "### Read data from bulk download"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hjMXVwUSlLHM"
      },
      "outputs": [],
      "source": [
        "bills_df = pd.read_csv('MN/2021-2022/MN_2021-2022_bills.csv')\n",
        "bills_df['classification'] = bills_df['classification'].apply(lambda x: literal_eval(x))\n",
        "bills_df['subject'] = bills_df['subject'].apply(lambda x: literal_eval(x))\n",
        "bills_df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tHkElQFyLw3N"
      },
      "source": [
        "### Select only bill data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ap0kj2tzLwCx"
      },
      "outputs": [],
      "source": [
        "bills_df['classification'] = bills_df['classification'].apply(lambda x: ';'.join(x))\n",
        "bills_df = bills_df[bills_df['classification'] == 'bill']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BvzIGJdHlLHN"
      },
      "source": [
        "### Drop duplicates and extract bill names"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3r7hZpu7lLHO"
      },
      "outputs": [],
      "source": [
        "bills_df = bills_df.drop_duplicates('id').reset_index(drop=True)\n",
        "bills_names = bills_df['title'].tolist()\n",
        "bills_names[:5]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kxQqZAkQlLHP"
      },
      "source": [
        "### Load Language Model for vectorization (add text vector image)\n",
        "Language Models are a specific type of models trained to predict a word in a sentence based on the words in its context. This type of task, matched with large amounts of parameters and data (LLM) has been used to generate high quality text embeddings, which are representations of words and sentences as vectors that can be used for downstream tasks like NER, QA, classification etc."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O2Ckk8CzlLHQ"
      },
      "outputs": [],
      "source": [
        "# distilbert-base-cased , legalbert, xlm-roberta-base, microsoft/deberta-base\n",
        "encoder = pipeline(\"feature-extraction\", model='distilbert-base-cased', device=0)\n",
        "embs = encoder(bills_names)\n",
        "cls_embs = torch.tensor([emb[0][0] for emb in embs])\n",
        "cls_embs = normalize(cls_embs)\n",
        "print(cls_embs[:5])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5sfS7z30lLHQ"
      },
      "source": [
        "### Reduce vectors dimensionality with TSNE\n",
        "A non-linear dimensionality reduction techique to help us visualize high dimensional data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "shfCvW2JlLHR"
      },
      "outputs": [],
      "source": [
        "reducer = TSNE(n_components=2, perplexity=10)\n",
        "plot_embs = reducer.fit_transform(cls_embs)\n",
        "bills_df[['dim1', 'dim2']] = pd.DataFrame(plot_embs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f6Rlmp6hlLHT"
      },
      "source": [
        "### Find policy topic clusters\n",
        "Use KMeans clustering algorithm to try no find groups of bills similar to each other and different to the rest of the bills"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F3fvnGpmlLHT"
      },
      "outputs": [],
      "source": [
        "# best clusters: distilbert, kmeans(9) xlm, kmeans(5)\n",
        "identifier = KMeans(5)\n",
        "bills_df['pred_labels'] = identifier.fit_predict(cls_embs)\n",
        "bills_df['pred_labels'] = bills_df['pred_labels'].astype(str)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PyLjak4AlLHR"
      },
      "source": [
        "### Find the right number of groups\n",
        "Iterate the KMeans algorithm over the number of groups"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mrj1QpuulLHS"
      },
      "outputs": [],
      "source": [
        "# inertias = []\n",
        "# cluster_sizes = list(range(2,50))\n",
        "# for k in cluster_sizes:\n",
        "#     kmeans = KMeans(n_clusters=k)\n",
        "#     kmeans.fit(cls_embs)\n",
        "#     inertias.append(kmeans.inertia_)\n",
        "# plt.plot(cluster_sizes, inertias)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PVJU3rXDlLHU"
      },
      "source": [
        "### Simple plot presenting the groups in the reduced dimensionality"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9yPdR2MZlLHU"
      },
      "outputs": [],
      "source": [
        "sns.scatterplot(x=\"dim1\", y=\"dim2\", data=bills_df, hue=\"pred_labels\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nh6VDXw2lLHV"
      },
      "source": [
        "### Plots results interactively"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JBKrSliXlLHV"
      },
      "outputs": [],
      "source": [
        "fig = px.scatter(\n",
        "    bills_df, x='dim1', y='dim2', color='pred_labels',\n",
        "    hover_data=['title'])\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "toOgR6XHlLHW"
      },
      "source": [
        "### Manually review embeddings\n",
        "Compare a bill name with the closest bill names available in the vector space using Cosine Similarity"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dsgjw10NlLHW"
      },
      "outputs": [],
      "source": [
        "# Support functions\n",
        "def test_embs(cls_embs, bills_df):    \n",
        "    embs_sims = cosine_similarity(cls_embs)\n",
        "    temp_dfs = []\n",
        "    for i in range(cls_embs.shape[0]):\n",
        "        bill_name = bills_df.loc[i, 'title']\n",
        "        bill_subject = bills_df.loc[i, 'subject']\n",
        "        emb_sims = embs_sims[i]\n",
        "        max_sims_ids = np.argsort(emb_sims)[-6:-1]\n",
        "        max_sims = emb_sims[max_sims_ids]\n",
        "        sim_bills_names = bills_df.loc[max_sims_ids, 'title']\n",
        "        sim_bills_subject = bills_df.loc[max_sims_ids, 'subject']\n",
        "        topic_id = bills_df.loc[i, 'pred_labels']\n",
        "        temp_df = pd.DataFrame({\n",
        "            'bill_name': [bill_name]*5,\n",
        "            'sim_bill_name': sim_bills_names,\n",
        "            'bill_subject': [bill_subject]*5,\n",
        "            'sim_bill_subject': sim_bills_subject,\n",
        "            'sim_score': max_sims,\n",
        "        })\n",
        "        temp_dfs.append(temp_df)\n",
        "    vect_eval_df = pd.concat(temp_dfs)\n",
        "    return vect_eval_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vnkpXFV-lLHW"
      },
      "outputs": [],
      "source": [
        "vect_eval_df = test_embs(cls_embs, bills_df)\n",
        "vect_eval_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ge6fRHRFeLoW"
      },
      "source": [
        "### Finding information about topics per bill"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zeU17xkGeRDB"
      },
      "outputs": [],
      "source": [
        "subjects_count = bills_df['subject'].apply(len)\n",
        "subjects_count.describe()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WD5_zryTlLHX"
      },
      "source": [
        "### Topic prevalence in the state session"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "chk6VoELdNTn"
      },
      "outputs": [],
      "source": [
        "subjects = bills_df['subject'].explode(ignore_index=True)\n",
        "subjects.value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eJJ6aFgElLHY"
      },
      "source": [
        "### Conclusions and next steps\n",
        "- Most bills are about more than one topic\n",
        "- A clustering algorithm may not be the best way to identify multiple topics inside a bill\n",
        "- We will likely require a dataset with bills and their corresponding topics\n",
        "    \n",
        "### Ideas for next steps\n",
        "- Train classification model with MN labels. Does the knowledge transfers to different jurisdictions?\n",
        "- Try different clustering algorithms and hyperparameters\n",
        "- Test different dimensionality reduction algorithms\n",
        "- Replace LM with a bigger or specialized model (ex: Roberta, Legalbert)\n",
        "- Whatever you want to try!\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.12 (default, Sep  2 2022, 17:14:49) \n[Clang 13.1.6 (clang-1316.0.21.2.3)]"
    },
    "vscode": {
      "interpreter": {
        "hash": "1cedee4db0691545d085713a50f62e4923b3397a499dc63cd0ba8de90403faa3"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
